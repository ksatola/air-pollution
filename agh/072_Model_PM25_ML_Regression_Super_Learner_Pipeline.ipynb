{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models stacking pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from model import (\n",
    "    get_pm25_data_for_modelling,\n",
    "    #split_df_for_ts_modelling_percentage,\n",
    "    #split_df_for_ts_modelling_date_range\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Reads JSON file.\n",
    "    :param json_path: full path to JSON file\n",
    "    :return: Python dictionary\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as infile:\n",
    "        return json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files: https://github.com/ksatola/air-polution/tree/master/agh/data\n",
    "\n",
    "def get_pm25_data_for_modelling(model_type: str = 'ml',\n",
    "                                forecast_type: str = 'h') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads HDF file with analytical view prepared for time series or machine learning modelling.\n",
    "    :param model_type: 'ts' for time series analytical model or 'ml' for machine learning model\n",
    "    :param forecast_type: 'd' for daily or 'h' for hourly data\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\"\n",
    "    config = read_json('../config/pm25_model.json')\n",
    "    data_folder = config['data_folder']\n",
    "\n",
    "    if model_type == 'ml':\n",
    "        if forecast_type == 'h':\n",
    "            data_file_hdf = data_folder + 'dfpm25_2008-2018_ml_24hours_lags.hdf'\n",
    "        else:\n",
    "            data_file_hdf = data_folder + 'dfpm25_2008-2018_ml_7days_lags.hdf'\n",
    "    else:\n",
    "        if forecast_type == 'h':\n",
    "            data_file_hdf = data_folder + 'dfpm25_2008-2018_hourly.hdf'\n",
    "        else:\n",
    "            data_file_hdf = data_folder + 'dfpm25_2008-2018_daily.hdf'\n",
    "\n",
    "    df = pd.read_hdf(path_or_buf=data_file_hdf, key=\"df\")\n",
    "    #logger.info(f'Dataframe loaded: {data_file_hdf}')\n",
    "    #logger.info(f'Dataframe size: {df.shape}')\n",
    "    print(f'Dataframe loaded: {data_file_hdf}')\n",
    "    print(f'Dataframe size: {df.shape}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded: /Users/ksatola/Documents/git/air-polution/agh/data/dfpm25_2008-2018_ml_7days_lags.hdf\n",
      "Dataframe size: (4014, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>-16.374909</td>\n",
       "      <td>-47.645172</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.625808</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>-16.374909</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.621035</td>\n",
       "      <td>13.625808</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.678291</td>\n",
       "      <td>-21.621035</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.641890</td>\n",
       "      <td>8.678291</td>\n",
       "      <td>13.625808</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t        t-1        t-3        t-4        t-5  month  day  hour  \\\n",
       "0   4.290823   7.381350   5.134971 -16.374909 -47.645172      1    6     0   \n",
       "1  13.625808   4.290823  17.628909   5.134971 -16.374909      1    7     0   \n",
       "2 -21.621035  13.625808   7.381350  17.628909   5.134971      1    8     0   \n",
       "3   8.678291 -21.621035   4.290823   7.381350  17.628909      1    9     0   \n",
       "4  11.641890   8.678291  13.625808   4.290823   7.381350      1   10     0   \n",
       "\n",
       "   dayofyear  weekofyear  dayofweek  quarter  season  \n",
       "0          6           1          6        1       1  \n",
       "1          7           2          0        1       1  \n",
       "2          8           2          1        1       1  \n",
       "3          9           2          2        1       1  \n",
       "4         10           2          3        1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd = get_pm25_data_for_modelling('ml', 'd')\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_for_ml_modelling(data: pd.DataFrame, \n",
    "                              target_col: str = 't', \n",
    "                              train_size: float = 0.8) -> (pd.DataFrame, \n",
    "                                                           pd.DataFrame, \n",
    "                                                           pd.DataFrame, \n",
    "                                                           pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Splits pandas DataFrame (columns as features, rows as observations) into train/test split \n",
    "    data frames separately for independent and dependent features.\n",
    "    :param data: pandas DataFrame\n",
    "    :param target_col: name of the target column\n",
    "    :param train_size: train/test split ratio, 0-1, specifies how much data should be but in the\n",
    "    train data set\n",
    "    :return: tuple of four pandas DataFrames: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Split dataset into independent variables dataset columns and dependent variable column\n",
    "    # X = df.iloc[:, 1:]\n",
    "    # y = df.iloc[:, :1]\n",
    "    X = data.copy()\n",
    "    y = X.pop(target_col)\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=train_size,\n",
    "                                                        random_state=123)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_df_for_ml_modelling(data=dfd, \n",
    "                                                             target_col='t', \n",
    "                                                             train_size=0.02) # train_size=0.00024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3933, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_for_regression() -> list:\n",
    "    \"\"\"\n",
    "    Defines a list of regression models to be used in the modelling.\n",
    "    :return: list of base sklearn models\n",
    "    \"\"\"\n",
    "    models = [LinearRegression(),\n",
    "              ElasticNet(),\n",
    "              SVR(gamma='scale'),\n",
    "              DecisionTreeRegressor(),\n",
    "              KNeighborsRegressor(),\n",
    "              AdaBoostRegressor(),\n",
    "              BaggingRegressor(n_estimators=10),\n",
    "              RandomForestRegressor(n_estimators=10),\n",
    "              ExtraTreesRegressor(n_estimators=10)\n",
    "              ]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))\n",
      "('ElasticNet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False))\n",
      "('SVR', SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))\n",
      "('DecisionTreeRegressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best'))\n",
      "('KNeighborsRegressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform'))\n",
      "('AdaBoostRegressor', AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                 n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                 warm_start=False))\n",
      "('RandomForestRegressor', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False))\n",
      "('ExtraTreesRegressor', ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
      "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                    max_samples=None, min_impurity_decrease=0.0,\n",
      "                    min_impurity_split=None, min_samples_leaf=1,\n",
      "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                    n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                    random_state=None, verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "# Define regression models in scope\n",
    "reg_models = get_models_for_regression()\n",
    "models = []\n",
    "\n",
    "for model in reg_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ml_models(X_train: pd.DataFrame,\n",
    "                    y_train: pd.DataFrame,\n",
    "                    models: list,\n",
    "                    n_splits: int,\n",
    "                    metric: str,\n",
    "                    metric_label: str) -> (list, list, list):\n",
    "    \"\"\"\n",
    "    Calculates a metric for a dataset and list of models.\n",
    "    :param X_train: pandas DataFrame with independent variables\n",
    "    :param y_train: pandas DataFrame with dependent variable\n",
    "    :param models: list of models\n",
    "    :param n_splits: number of splits for kFold cross validation\n",
    "    :param metric: scoring name as defined in\n",
    "    https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    :param metric_label: label for the scoring name\n",
    "    :return: tuple of three lists: output strings, cross validation results for each model,\n",
    "    model name\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    results = []\n",
    "    output = []\n",
    "\n",
    "    for name, model in models:\n",
    "        names.append(name)\n",
    "        try:\n",
    "        # Not all scoring metrics are available for all models\n",
    "            kfold = KFold(n_splits=n_splits)\n",
    "            cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=metric)\n",
    "            results.append(cv_results)\n",
    "            output.append(\n",
    "            f'{name}, {metric_label} {-cv_results.mean()}, (std. dev. {cv_results.std()})')\n",
    "        except:\n",
    "            output.append(f'{name} {metric_label} metric unavailable)')\n",
    "\n",
    "    return output, results, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 13.143886676634612, (std. dev. 0.42758394413212353)\n",
      "ElasticNet, RMSE 13.131853794028634, (std. dev. 0.43576815454789974)\n",
      "SVR, RMSE 13.823720574691311, (std. dev. 0.2945517705423598)\n",
      "DecisionTreeRegressor, RMSE 19.15617659638259, (std. dev. 0.8308203555667868)\n",
      "KNeighborsRegressor, RMSE 14.588892279746142, (std. dev. 0.4463272629786315)\n",
      "AdaBoostRegressor, RMSE 13.98362680122381, (std. dev. 0.24964742384039304)\n",
      "BaggingRegressor, RMSE 14.298376666984037, (std. dev. 0.2468847093716878)\n",
      "RandomForestRegressor, RMSE 14.392480519903694, (std. dev. 0.45607276871301794)\n",
      "ExtraTreesRegressor, RMSE 14.393524860652239, (std. dev. 0.4362151151877618)\n",
      "CPU times: user 5.7 s, sys: 255 ms, total: 5.95 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Perform initial ranking\n",
    "scores, results, names = score_ml_models(X_train=X_train,\n",
    "                                         y_train=y_train,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "fig.suptitle('Algorithms Comparison - RMSE')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig('images/ml_comparison_rmse_d.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning (2 methods & 3 exemplary models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 4 µs, total: 14 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LinearRegression\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
    "    \"max_iter\": [1, 10, 100, 1000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "model = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_cv2(X_train, y_train, model, param_grid, scoring, num_folds = 6, seed = 123):\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score'] \n",
    "    stds = grid_result.cv_results_['std_test_score'] \n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "        #print(\"{:0.2f} ({:0.2f}) with: {}\".format(mean, stdev, param))\n",
    "    #print('-------')\n",
    "    print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.125668218478436 using {'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.7000000000000001, 'max_iter': 10, 'selection': 'random'}\n",
      "CPU times: user 2min 7s, sys: 14.7 s, total: 2min 22s\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 4 µs, total: 35 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# AdaBoostRegressor\n",
    "param_grid = {\n",
    "    \"base_estimator\": [models[0][1]],\n",
    "    \"n_estimators\": [100, 200],#, 500, 1000, 5000, 10000],\n",
    "    \"loss\": [\"linear\"]#, \"square\", \"exponential\"]\n",
    "}\n",
    "model = models[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_search_cv2(X_train, y_train, model, param_grid, scoring, num_folds = 6, seed = 123):\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    grid = RandomizedSearchCV(estimator=model,\n",
    "                            param_distributions=param_grid,\n",
    "                            scoring=scoring,\n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            n_iter=1000)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score'] \n",
    "    stds = grid_result.cv_results_['std_test_score'] \n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "        #print(\"{:0.2f} ({:0.2f}) with: {}\".format(mean, stdev, param))\n",
    "    #print('-------')\n",
    "    print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.280370252663058 using {'n_estimators': 200, 'loss': 'linear', 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "CPU times: user 253 ms, sys: 137 ms, total: 390 ms\n",
      "Wall time: 1.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    1.5s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoostRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 µs, sys: 41 µs, total: 62 µs\n",
      "Wall time: 15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BaggingRegressor\n",
    "param_grid = {\n",
    "    \"base_estimator\": [models[0][1]],\n",
    "    \"n_estimators\": [100, 200],#, 500, 1000, 5000, 10000],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "model = models[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best: -13.141751073262611 using {'n_jobs': -1, 'n_estimators': 100, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "CPU times: user 132 ms, sys: 75.9 ms, total: 207 ms\n",
      "Wall time: 2.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BaggingRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate best models on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True,\n",
      "                 fit_intercept={'alpha': 0.1, 'fit_intercept': True,\n",
      "                                'l1_ratio': 0.9, 'max_iter': 10,\n",
      "                                'selection': 'cyclic'},\n",
      "                 n_jobs=None, normalize=False))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=LinearRegression(copy_X=True,\n",
      "                                                 fit_intercept=True,\n",
      "                                                 n_jobs=None, normalize=False),\n",
      "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                 max_samples=1.0, n_estimators=500, n_jobs=-1, oob_score=False,\n",
      "                 random_state=None, verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "best_models = [\n",
    "    LinearRegression({'selection': 'cyclic', 'max_iter': 10, 'l1_ratio': 0.9, 'fit_intercept': True, 'alpha': 0.1}),\n",
    "    #ElasticNet(**{'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}),\n",
    "    BaggingRegressor(**{'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'bootstrap': True, 'n_estimators': 500, 'n_jobs': -1}),\n",
    "    #RandomForestRegressor(**{'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'ccp_alpha': 0}),\n",
    "    #ExtraTreesRegressor(**{'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_depth': 20, 'ccp_alpha': 0})\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for model in best_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 13.048955489499978, (std. dev. 1.579505939681471)\n",
      "BaggingRegressor, RMSE 12.956500052057915, (std. dev. 1.4879616402005373)\n"
     ]
    }
   ],
   "source": [
    "scores, results, names = score_ml_models(X_train=X_test,\n",
    "                                         y_train=y_test,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\")\n",
    "\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super learner (stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "BaggingRegressor\n"
     ]
    }
   ],
   "source": [
    "# Define regression models in scope\n",
    "models = best_models\n",
    "\n",
    "for model in models:\n",
    "    print(type(model).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical view for the Super learner (based on predictions of basic models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analytical_view_for_meta_model(X_train: pd.DataFrame,\n",
    "                                       y_train: pd.DataFrame,\n",
    "                                       models: list,\n",
    "                                       n_splits: int = 10\n",
    "                                       ) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Builds an analytical view based on kFold predictions of base models to be used by another\n",
    "    model (out-of-fold predictions).\n",
    "    :param X_train: input variables (pandas DataFrame)\n",
    "    :param y_train: target variables (pandas DataFrame)\n",
    "    :param models: list of base models\n",
    "    :param n_splits: number of KFold splits\n",
    "    :return: tuple of two pandas DataFrames, one with new input variables, and second with\n",
    "    corresponding target variables (a copy of y_train)\n",
    "    \"\"\"\n",
    "\n",
    "    # Define split of data\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    # Prepare empty data frame with column names (columns as models)\n",
    "    columns = [type(model).__name__ for model in models]\n",
    "    # and add target column\n",
    "    columns = columns.append(y_train.columns[0])\n",
    "    meta_X = pd.DataFrame(columns=columns)\n",
    "\n",
    "    cv_fold_number = 1\n",
    "\n",
    "    for train_indices, test_indices in kfold.split(X_train):\n",
    "        #logger.debug(f'train: {train_indices}, len: {len(train_indices)}')\n",
    "        #logger.debug(f'test: {test_indices}, len: {len(test_indices)}')\n",
    "\n",
    "        #logger.info(f'CV fold number -> {cv_fold_number}')\n",
    "        print(f'CV fold number -> {cv_fold_number}')\n",
    "        cv_fold_number += 1\n",
    "\n",
    "        # Get data\n",
    "        train_X, test_X = X_train.iloc[train_indices], X_train.iloc[test_indices]\n",
    "        train_y, test_y = y_train.iloc[train_indices], y_train.iloc[test_indices]\n",
    "        #logger.debug(f'train_indices {train_indices.shape}')\n",
    "        #logger.debug(f'test_indices {test_indices.shape}')\n",
    "\n",
    "        # Add target variable\n",
    "        fold_yhats = test_y.copy()\n",
    "\n",
    "        # Fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model_name = type(model).__name__\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            #logger.info(model_name)\n",
    "            #logger.debug(f'train_X.shape {train_X.shape}')\n",
    "            #logger.debug(f'train_y.shape {train_y.shape}')\n",
    "            #logger.debug(f'yhat.shape {yhat.shape}')\n",
    "            print(model_name)\n",
    "\n",
    "            # Build fold-level results data frame, models as features\n",
    "            fold_yhats[f'{model_name}'] = yhat\n",
    "\n",
    "        #logger.debug(f'meta_X shape {meta_X.shape}')\n",
    "        meta_X = pd.concat([meta_X, fold_yhats])\n",
    "\n",
    "    # Take the target variable out from the dataset\n",
    "    meta_y = meta_X.pop(y_train.columns[0]).to_frame()\n",
    "\n",
    "    return meta_X, meta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.986208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>0.543645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>-19.756946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>11.018518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>-4.554063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>25.192456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>0.237439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>-2.599563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>-2.691479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>0.175861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3933 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              t\n",
       "565    1.986208\n",
       "3510   0.543645\n",
       "2845 -19.756946\n",
       "380   11.018518\n",
       "809   -4.554063\n",
       "...         ...\n",
       "1122  25.192456\n",
       "1346   0.237439\n",
       "3454  -2.599563\n",
       "3437  -2.691479\n",
       "3582   0.175861\n",
       "\n",
       "[3933 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold number -> 1\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 2\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 3\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 4\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 5\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 6\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 7\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 8\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 9\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CV fold number -> 10\n",
      "LinearRegression\n",
      "BaggingRegressor\n",
      "CPU times: user 2.29 s, sys: 191 ms, total: 2.48 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_X, meta_y = get_analytical_view_for_meta_model(X_train, y_train.to_frame(), models, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>BaggingRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>9.520451</td>\n",
       "      <td>9.465197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>-0.985653</td>\n",
       "      <td>-1.054339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.731567</td>\n",
       "      <td>1.803878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>-0.092566</td>\n",
       "      <td>-0.061413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>0.607761</td>\n",
       "      <td>0.584574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LinearRegression  BaggingRegressor\n",
       "380           9.520451          9.465197\n",
       "1700         -0.985653         -1.054339\n",
       "602           1.731567          1.803878\n",
       "2415         -0.092566         -0.061413\n",
       "2256          0.607761          0.584574"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>11.018518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>-8.015220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>4.828153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>-4.309594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>18.147460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t\n",
       "380   11.018518\n",
       "1700  -8.015220\n",
       "602    4.828153\n",
       "2415  -4.309594\n",
       "2256  18.147460"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_base_models(X_train: pd.DataFrame,\n",
    "                    y_train: pd.DataFrame,\n",
    "                    models) -> list:\n",
    "    \"\"\"\n",
    "    Fits all base models on the training dataset.\n",
    "    :param X_train: input variables (pandas DataFrame)\n",
    "    :param y_train: target variables (pandas DataFrame)\n",
    "    :param models: list of base models\n",
    "    :return: list of fitted sklearn models\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64.4 ms, sys: 10.1 ms, total: 74.5 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit base models on entire training dataset\n",
    "models = fit_base_models(X_train, y_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_meta_model(X_train: pd.DataFrame,\n",
    "                   y_train: pd.DataFrame,\n",
    "                   meta_model: BaseEstimator = LinearRegression()) -> BaseEstimator:\n",
    "    \"\"\"\n",
    "    Fits a meta model on the training dataset.\n",
    "    :param X_train: input variables (pandas DataFrame)\n",
    "    :param y_train: target variables (pandas DataFrame)\n",
    "    :param meta_model: sklearn regression estimator class\n",
    "    :return: fitted sklearn model\n",
    "    \"\"\"\n",
    "    model = meta_model\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 ms, sys: 906 µs, total: 4.01 ms\n",
      "Wall time: 3.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the meta model (using sklearn.linear_model.LinearRegression)\n",
    "meta_model = fit_meta_model(meta_X, meta_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(observed: pd.Series, predicted: pd.Series) -> np.float:\n",
    "    \"\"\"\n",
    "    Calculates RMSE - Root Mean Squared Error between two series\n",
    "    :param observed: pandas series with observed values (the truth)\n",
    "    :param predicted: pandas series with predicted values\n",
    "    :return: RMSE value\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(observed, predicted)\n",
    "    rmse = round(np.sqrt(mse), 4)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_test: pd.DataFrame, y_test: pd.DataFrame, models: list) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates a list of models on a dataset using RMSE (Root Mean Squared Error).\n",
    "    :param X_test: input variables (pandas DataFrame)\n",
    "    :param y_test: target variables (pandas DataFrame)\n",
    "    :param models: list of base models\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        yhat = model.predict(X_test)\n",
    "        #logger.info(f'{model.__class__.__name__} RMSE {get_rmse(y_test, yhat)}')\n",
    "        print(f'{model.__class__.__name__} RMSE {get_rmse(y_test, yhat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE 11.305\n",
      "BaggingRegressor RMSE 11.3016\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the base models on the holdout (test) dataset\n",
    "evaluate_models(X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_super_learner(X_test: pd.DataFrame,\n",
    "                               y_test: pd.DataFrame,\n",
    "                               models: list,\n",
    "                               meta_model: BaseEstimator) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Makes predictions with stacked (meta) model.\n",
    "    :param X_test: input variables (pandas DataFrame)\n",
    "    :param y_test: target variables (pandas DataFrame)\n",
    "    :param models: list of trained base models\n",
    "    :param meta_model: sklearn model used for stacking\n",
    "    :return: tuple of two pandas DataFrames, one with meta-model predictions, and second with\n",
    "    corresponding target variables (a copy of y_test)\n",
    "    \"\"\"\n",
    "    # yhats = y_test.copy()\n",
    "\n",
    "    # Prepare empty data frame with column names (columns as models)\n",
    "    columns = [type(model).__name__ for model in models]\n",
    "    # and add target column\n",
    "    columns = columns.append(y_test.columns[0])\n",
    "    models_yhat = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Add target variable\n",
    "    yhats = y_test.copy()\n",
    "\n",
    "    for model in models:\n",
    "        model_name = type(model).__name__\n",
    "        yhat = model.predict(X_test)\n",
    "        #logger.info(model_name)\n",
    "        print(model_name)\n",
    "        #logger.debug(f'yhat.shape {yhat.shape}')\n",
    "\n",
    "        # Build results data frame, models as features\n",
    "        yhats[f'{model_name}'] = yhat\n",
    "\n",
    "    models_yhat = pd.concat([models_yhat, yhats])\n",
    "    # Take the target variable out from the dataset\n",
    "    meta_target = models_yhat.pop(y_test.columns[0]).to_frame()\n",
    "\n",
    "    # Predict\n",
    "    meta_yhat = meta_model.predict(models_yhat)\n",
    "\n",
    "    return meta_yhat, meta_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Super learner (on test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "BaggingRegressor\n",
      "Super Learner RMSE 11.2233\n"
     ]
    }
   ],
   "source": [
    "# Use the super learner (base and meta models) to make predictions on the holdout dataset \n",
    "# and evaluate the performance of the approach\n",
    "meta_yhat, meta_target = predict_with_super_learner(X_test, y_test.to_frame(), models, meta_model)\n",
    "print(f'Super Learner RMSE {get_rmse(y_test, meta_yhat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
